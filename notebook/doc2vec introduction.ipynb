{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec 的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.imooc.com/article/41650\n",
    "* gensim 基于Doc2vec 论文 实现的代码-提供了Doc2vec 训练的案例  <br>\n",
    "https://radimrehurek.com/gensim/models/doc2vec.html#gensim.models.doc2vec.Doc2Vec\n",
    "* Doc2vec 论文 https://arxiv.org/abs/1405.4053v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doc2Vec 或者叫做 paragraph2vec, sentence embeddings，是一种非监督式算法，可以获得sentences/paragraphs/documents 的向量表达，是 word2vec 的拓展。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec 两种实现方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2013 年 Mikolov 提出了 word2vec 来学习单词的向量表示 ,可以将 word 表示成向量形式，那么句子／段落／文档是否也可以只用一个向量表示？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法1: 先得到 word 的向量表示，然后用一个简单的平均来代表文档。 <br>\n",
    "方法2:然后用一个简单的平均来代表文档。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dbow (distributed bag of words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python gensim 中实现\n",
    "# model = gensim.models.Doc2Vec(documents,dm = 0, alpha=0.1, size= 20, min_alpha=0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* dm (distributed memory) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## python gensim \n",
    "## model = gensim.models.Doc2Vec(documents,dm = 1, alpha=0.1, size= 20, min_alpha=0.025)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二者在 gensim 实现时的区别是 dm = 0 还是 1.\n",
    "\n",
    "Doc2Vec 的目的是获得文档的一个固定长度的向量表达。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据：多个文档，以及它们的标签，可以用标题作为标签。  \n",
    "影响模型准确率的因素：语料的大小，文档的数量，越多越高；文档的相似性，越相似越好。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['human', 'interface', 'computer'],\n",
       " ['survey', 'user', 'computer', 'system', 'response', 'time'],\n",
       " ['eps', 'user', 'interface', 'system'],\n",
       " ['system', 'human', 'system', 'eps'],\n",
       " ['user', 'response', 'time'],\n",
       " ['trees'],\n",
       " ['graph', 'trees'],\n",
       " ['graph', 'minors', 'trees'],\n",
       " ['graph', 'minors', 'survey']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  数据的格式，对于中文的文章，我们需要分词\n",
    "common_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=['human', 'interface', 'computer'], tags=[0]),\n",
       " TaggedDocument(words=['survey', 'user', 'computer', 'system', 'response', 'time'], tags=[1]),\n",
       " TaggedDocument(words=['eps', 'user', 'interface', 'system'], tags=[2]),\n",
       " TaggedDocument(words=['system', 'human', 'system', 'eps'], tags=[3]),\n",
       " TaggedDocument(words=['user', 'response', 'time'], tags=[4]),\n",
       " TaggedDocument(words=['trees'], tags=[5]),\n",
       " TaggedDocument(words=['graph', 'trees'], tags=[6]),\n",
       " TaggedDocument(words=['graph', 'minors', 'trees'], tags=[7]),\n",
       " TaggedDocument(words=['graph', 'minors', 'survey'], tags=[8])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TaggedDocument : doc 和 i 组成\n",
    "documents = [TaggedDocument(doc,[i])  for i,doc in enumerate(common_texts)]\n",
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec 模型训练\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存\n",
    "model.save(\"doc2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型加载\n",
    "model2 = Doc2Vec.load(\"doc2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer vector for a new document:\n",
    "text_words = [\"system\", \"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08685704  0.00889632 -0.01070497 -0.06270082 -0.01931767]\n"
     ]
    }
   ],
   "source": [
    "vector = model2.infer_vector(text_words)\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述过程，就是我们通过Doc2Vec 的方式提取文本的特征，然后给予这些这些特征就可以进行文本分类训练啦"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 项目总结：\n",
    "* Doc2vec 模型 doc_list 的格式 需要分词的内容\n",
    "* TaggedDocument 我们可以查看对应的源码，可以自己按照这个格式实现自己的TaggedDocument 格式的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
