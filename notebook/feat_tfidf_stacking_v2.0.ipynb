{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"D:/ML_Study/2017-CCF-BDCI-AIJudge\")\n",
    "import pandas as pd\n",
    "from config.db_config import Config\n",
    "import numpy as np\n",
    "from utils import LOGGER\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def micro_avg_f1(y_true, y_pred):\n",
    "    '''\n",
    "    分类 评估函数\n",
    "    :param y_true: 样本实际类别\n",
    "    :param y_pred: 预测类别\n",
    "    :return:\n",
    "    '''\n",
    "    return f1_score(y_true, y_pred, average='micro')\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    '''\n",
    "    加载数据\n",
    "    :param data_path:\n",
    "    :return:\n",
    "    '''\n",
    "    train_df = pd.read_csv(data_path, encoding='utf-8', sep=',')\n",
    "    train_df = train_df.dropna()\n",
    "    train_df['penalty'] = train_df['penalty'].astype(int)\n",
    "    return train_df\n",
    "\n",
    "\n",
    "def get_words_list(raw_documents):\n",
    "    '''\n",
    "        获取tfidf 数值化的输入数据\n",
    "    :return: 数据类型为列表，其中的元素也为列表  [[word1 word2.....],[word11 word12....]]\n",
    "    '''\n",
    "    words_list = []\n",
    "    for document in raw_documents:\n",
    "        words_list.append(document.split())\n",
    "    return words_list\n",
    "\n",
    "\n",
    "def words_list2tfidf_feature(raw_documents):\n",
    "    words_list = get_words_list(raw_documents)\n",
    "    ## 1. TfidfVectorizer模型\n",
    "    '''\n",
    "    调用sklearn.feature_extraction.text库的TfidfVectorizer方法实例化模型对象。\n",
    "    TfidfVectorizer方法需要4个参数。\n",
    "    第1个参数是分词结果，数据类型为列表，其中的元素也为列表；\n",
    "    第2个关键字参数stop_words是停顿词，数据类型为列表；\n",
    "    第3个关键字参数min_df是词频低于此值则忽略，数据类型为int或float;\n",
    "    第4个关键字参数max_df是词频高于此值则忽略，数据类型为Int或float。\n",
    "    查看TfidfVectorizer方法的更多参数用法，\n",
    "    官方文档链接：http://sklearn.apachecn.org/cn/0.19.0/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "    '''\n",
    "    tfidf = TfidfVectorizer(words_list, min_df=3, max_df=0.95)\n",
    "    '''\n",
    "    第1行代码查看向量化的维数，即特征的维数；\n",
    "    第2行代码调用TfidfVectorizer对象的fit_transform方法获得特征矩阵赋值给X；\n",
    "    第3行代码查看特征矩阵的形状。\n",
    "    '''\n",
    "    X = tfidf.fit_transform(raw_documents)\n",
    "    print('词表大小:', len(tfidf.vocabulary_))\n",
    "    print(X.shape)\n",
    "    return X\n",
    "\n",
    "\n",
    "def df_target2label(target):\n",
    "    '''\n",
    "    调用sklearn.preprocessing库的LabelEncoder方法对文章分类做标签编码。\n",
    "    :param target:\n",
    "    :return:\n",
    "    '''\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(target)\n",
    "    return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. lr 特征提取\n",
    "def tfidf_clf_features(clf, X_train, X_test, y_train, y_test, num_class, seed=2019):\n",
    "    # 初始化stack ： 通过模型提取特征矩阵的数值\n",
    "    print(\"dataset size X_train={0},X_test={1},dim={2}\".format(X_train.shape[0], X_test.shape[0], X_test.shape[1]))\n",
    "    stack = np.zeros((X_train.shape[0], num_class))\n",
    "    stack_te = np.zeros((X_test.shape[0], num_class))\n",
    "    # 1. 交叉验证- 特征得分平均\n",
    "    k = 5\n",
    "    print(\"cross_validate k={0}\".format(k))\n",
    "    score_va = 0\n",
    "    score_te = 0\n",
    "    skf = StratifiedKFold(n_splits=k, random_state=seed)\n",
    "    for i, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        print(\"cross_validate.....i={0}\".format(i + 1))\n",
    "        train_data, val_data = X_train[train_index], X_train[val_index]\n",
    "        train_y, val_y = y_train[train_index], y_train[val_index]\n",
    "        # clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        clf.fit(train_data, train_y)\n",
    "        y_pred_val = clf.predict(val_data)\n",
    "        val_accuracy = micro_avg_f1(val_y, y_pred_val)\n",
    "        test_accuacy = micro_avg_f1(y_test, clf.predict(X_test))\n",
    "        LOGGER.log('val_dataset accuacy:%f' % val_accuracy)\n",
    "        LOGGER.log('test_dataset accuacy:%f' % test_accuacy)\n",
    "        score_va += val_accuracy\n",
    "        score_te += test_accuacy\n",
    "        y_pred_val_prob = clf.predict_proba(val_data)\n",
    "        y_pred_te_prob = clf.predict_proba(X_test)\n",
    "        stack[val_index] += y_pred_val_prob\n",
    "        stack_te += y_pred_te_prob\n",
    "    score_va /= k\n",
    "    score_te /= k\n",
    "    print(\"cross_validate success. print avg acc ...\")\n",
    "    LOGGER.log('val_dataset avg acc:%f' % score_va)\n",
    "    LOGGER.log('test_dataset avg acc:%f' % score_te)\n",
    "    # 2. lr... 提取的特征存储\n",
    "    stack_all = np.vstack([stack / k, stack_te / k])\n",
    "    return stack_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_size=200\n",
      "词表大小: 1343\n",
      "(200, 1343)\n",
      "num_class=8\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "# 1. 提取tfidf 格式特征 X,y\n",
    "train_df = load_data(config.data_csv_path)\n",
    "count = len(train_df)\n",
    "print(\"data_size={0}\".format(count))\n",
    "raw_documents = train_df['content']\n",
    "X = words_list2tfidf_feature(raw_documents)\n",
    "y = df_target2label(train_df['penalty'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "num_class = len(np.unique(y))\n",
    "print(\"num_class={0}\".format(num_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size X_train=140,X_test=60,dim=1343\n",
      "cross_validate k=5\n",
      "cross_validate.....i=1\n",
      "2019-03-25 17:33:15 val_dataset accuacy:0.516129\n",
      "2019-03-25 17:33:15 test_dataset accuacy:0.583333\n",
      "cross_validate.....i=2\n",
      "2019-03-25 17:33:15 val_dataset accuacy:0.533333\n",
      "2019-03-25 17:33:15 test_dataset accuacy:0.600000\n",
      "cross_validate.....i=3\n",
      "2019-03-25 17:33:15 val_dataset accuacy:0.518519\n",
      "2019-03-25 17:33:15 test_dataset accuacy:0.616667\n",
      "cross_validate.....i=4\n",
      "2019-03-25 17:33:15 val_dataset accuacy:0.615385\n",
      "2019-03-25 17:33:15 test_dataset accuacy:0.633333\n",
      "cross_validate.....i=5\n",
      "2019-03-25 17:33:15 val_dataset accuacy:0.576923\n",
      "2019-03-25 17:33:15 test_dataset accuacy:0.616667\n",
      "cross_validate success. print avg acc ...\n",
      "2019-03-25 17:33:15 val_dataset avg acc:0.552058\n",
      "2019-03-25 17:33:15 test_dataset avg acc:0.610000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_lr_0</th>\n",
       "      <th>tfidf_lr_1</th>\n",
       "      <th>tfidf_lr_2</th>\n",
       "      <th>tfidf_lr_3</th>\n",
       "      <th>tfidf_lr_4</th>\n",
       "      <th>tfidf_lr_5</th>\n",
       "      <th>tfidf_lr_6</th>\n",
       "      <th>tfidf_lr_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011970</td>\n",
       "      <td>0.125226</td>\n",
       "      <td>0.027079</td>\n",
       "      <td>0.005949</td>\n",
       "      <td>0.008986</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>0.005089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.014266</td>\n",
       "      <td>0.059491</td>\n",
       "      <td>0.025005</td>\n",
       "      <td>0.047042</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.006166</td>\n",
       "      <td>0.030519</td>\n",
       "      <td>0.005011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.108593</td>\n",
       "      <td>0.032227</td>\n",
       "      <td>0.009247</td>\n",
       "      <td>0.006541</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.008013</td>\n",
       "      <td>0.020794</td>\n",
       "      <td>0.005217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031528</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.015672</td>\n",
       "      <td>0.015025</td>\n",
       "      <td>0.075790</td>\n",
       "      <td>0.007087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028078</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>0.012173</td>\n",
       "      <td>0.008916</td>\n",
       "      <td>0.014038</td>\n",
       "      <td>0.009866</td>\n",
       "      <td>0.033342</td>\n",
       "      <td>0.007683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_lr_0  tfidf_lr_1  tfidf_lr_2  tfidf_lr_3  tfidf_lr_4  tfidf_lr_5  \\\n",
       "0    0.011970    0.125226    0.027079    0.005949    0.008986    0.005228   \n",
       "1    0.014266    0.059491    0.025005    0.047042    0.012500    0.006166   \n",
       "2    0.108593    0.032227    0.009247    0.006541    0.009368    0.008013   \n",
       "3    0.031528    0.032429    0.009179    0.013290    0.015672    0.015025   \n",
       "4    0.028078    0.085904    0.012173    0.008916    0.014038    0.009866   \n",
       "\n",
       "   tfidf_lr_6  tfidf_lr_7  \n",
       "0    0.010474    0.005089  \n",
       "1    0.030519    0.005011  \n",
       "2    0.020794    0.005217  \n",
       "3    0.075790    0.007087  \n",
       "4    0.033342    0.007683  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. 提取特征\n",
    "# 2.1 lr 提取特征\n",
    "clf = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "stack_all = tfidf_clf_features(clf, X_train, X_test, y_train, y_test, num_class)\n",
    "df_stack = pd.DataFrame(index=range(count))\n",
    "for i in range(stack_all.shape[1]):\n",
    "    df_stack['tfidf_lr_{}'.format(i)] = stack_all[:, i]\n",
    "df_stack.to_csv(config.feat_tfidf_lr_prob, index=None, encoding='utf8')\n",
    "df_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size X_train=140,X_test=60,dim=1343\n",
      "cross_validate k=5\n",
      "cross_validate.....i=1\n",
      "2019-03-25 17:33:31 val_dataset accuacy:0.516129\n",
      "2019-03-25 17:33:31 test_dataset accuacy:0.583333\n",
      "cross_validate.....i=2\n",
      "2019-03-25 17:33:31 val_dataset accuacy:0.500000\n",
      "2019-03-25 17:33:31 test_dataset accuacy:0.583333\n",
      "cross_validate.....i=3\n",
      "2019-03-25 17:33:31 val_dataset accuacy:0.518519\n",
      "2019-03-25 17:33:31 test_dataset accuacy:0.583333\n",
      "cross_validate.....i=4\n",
      "2019-03-25 17:33:31 val_dataset accuacy:0.615385\n",
      "2019-03-25 17:33:31 test_dataset accuacy:0.650000\n",
      "cross_validate.....i=5\n",
      "2019-03-25 17:33:31 val_dataset accuacy:0.538462\n",
      "2019-03-25 17:33:31 test_dataset accuacy:0.616667\n",
      "cross_validate success. print avg acc ...\n",
      "2019-03-25 17:33:31 val_dataset avg acc:0.537699\n",
      "2019-03-25 17:33:31 test_dataset avg acc:0.603333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_bnb_0</th>\n",
       "      <th>tfidf_bnb_1</th>\n",
       "      <th>tfidf_bnb_2</th>\n",
       "      <th>tfidf_bnb_3</th>\n",
       "      <th>tfidf_bnb_4</th>\n",
       "      <th>tfidf_bnb_5</th>\n",
       "      <th>tfidf_bnb_6</th>\n",
       "      <th>tfidf_bnb_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.947141e-50</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>1.420321e-33</td>\n",
       "      <td>4.158327e-67</td>\n",
       "      <td>4.797524e-79</td>\n",
       "      <td>4.132211e-97</td>\n",
       "      <td>2.054234e-78</td>\n",
       "      <td>3.374777e-128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.792815e-30</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>2.637116e-27</td>\n",
       "      <td>3.539774e-15</td>\n",
       "      <td>5.040736e-61</td>\n",
       "      <td>1.119635e-79</td>\n",
       "      <td>4.309427e-45</td>\n",
       "      <td>4.516071e-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>1.586325e-33</td>\n",
       "      <td>1.944557e-53</td>\n",
       "      <td>5.119947e-66</td>\n",
       "      <td>9.064126e-68</td>\n",
       "      <td>5.461100e-74</td>\n",
       "      <td>7.675490e-55</td>\n",
       "      <td>1.118855e-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.525483e-07</td>\n",
       "      <td>4.104715e-02</td>\n",
       "      <td>3.892552e-31</td>\n",
       "      <td>2.529104e-27</td>\n",
       "      <td>3.223700e-33</td>\n",
       "      <td>1.563185e-38</td>\n",
       "      <td>1.589526e-01</td>\n",
       "      <td>1.318779e-76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.404584e-15</td>\n",
       "      <td>2.000000e-01</td>\n",
       "      <td>1.346761e-33</td>\n",
       "      <td>5.517362e-42</td>\n",
       "      <td>3.022733e-38</td>\n",
       "      <td>5.110157e-50</td>\n",
       "      <td>3.075211e-23</td>\n",
       "      <td>4.450799e-89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    tfidf_bnb_0   tfidf_bnb_1   tfidf_bnb_2   tfidf_bnb_3   tfidf_bnb_4  \\\n",
       "0  3.947141e-50  2.000000e-01  1.420321e-33  4.158327e-67  4.797524e-79   \n",
       "1  2.792815e-30  2.000000e-01  2.637116e-27  3.539774e-15  5.040736e-61   \n",
       "2  2.000000e-01  1.586325e-33  1.944557e-53  5.119947e-66  9.064126e-68   \n",
       "3  2.525483e-07  4.104715e-02  3.892552e-31  2.529104e-27  3.223700e-33   \n",
       "4  6.404584e-15  2.000000e-01  1.346761e-33  5.517362e-42  3.022733e-38   \n",
       "\n",
       "    tfidf_bnb_5   tfidf_bnb_6    tfidf_bnb_7  \n",
       "0  4.132211e-97  2.054234e-78  3.374777e-128  \n",
       "1  1.119635e-79  4.309427e-45  4.516071e-111  \n",
       "2  5.461100e-74  7.675490e-55  1.118855e-111  \n",
       "3  1.563185e-38  1.589526e-01   1.318779e-76  \n",
       "4  5.110157e-50  3.075211e-23   4.450799e-89  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # 2.2 BernoulliNB 提取特征\n",
    "clf = BernoulliNB()\n",
    "stack_all = tfidf_clf_features(clf, X_train, X_test, y_train, y_test, num_class)\n",
    "df_stack = pd.DataFrame(index=range(count))\n",
    "for i in range(stack_all.shape[1]):\n",
    "    df_stack['tfidf_bnb_{}'.format(i)] = stack_all[:, i]\n",
    "df_stack.to_csv(config.feat_tfidf_bnb_prob, index=None, encoding='utf8')\n",
    "df_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset size X_train=140,X_test=60,dim=1343\n",
      "cross_validate k=5\n",
      "cross_validate.....i=1\n",
      "2019-03-25 17:33:46 val_dataset accuacy:0.483871\n",
      "2019-03-25 17:33:46 test_dataset accuacy:0.566667\n",
      "cross_validate.....i=2\n",
      "2019-03-25 17:33:46 val_dataset accuacy:0.533333\n",
      "2019-03-25 17:33:46 test_dataset accuacy:0.583333\n",
      "cross_validate.....i=3\n",
      "2019-03-25 17:33:46 val_dataset accuacy:0.481481\n",
      "2019-03-25 17:33:46 test_dataset accuacy:0.600000\n",
      "cross_validate.....i=4\n",
      "2019-03-25 17:33:46 val_dataset accuacy:0.538462\n",
      "2019-03-25 17:33:46 test_dataset accuacy:0.566667\n",
      "cross_validate.....i=5\n",
      "2019-03-25 17:33:46 val_dataset accuacy:0.538462\n",
      "2019-03-25 17:33:46 test_dataset accuacy:0.583333\n",
      "cross_validate success. print avg acc ...\n",
      "2019-03-25 17:33:46 val_dataset avg acc:0.515122\n",
      "2019-03-25 17:33:46 test_dataset avg acc:0.580000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf_mnb_0</th>\n",
       "      <th>tfidf_mnb_1</th>\n",
       "      <th>tfidf_mnb_2</th>\n",
       "      <th>tfidf_mnb_3</th>\n",
       "      <th>tfidf_mnb_4</th>\n",
       "      <th>tfidf_mnb_5</th>\n",
       "      <th>tfidf_mnb_6</th>\n",
       "      <th>tfidf_mnb_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.180469</td>\n",
       "      <td>0.008034</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.001850</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008375</td>\n",
       "      <td>0.123705</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.024480</td>\n",
       "      <td>0.004474</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.023398</td>\n",
       "      <td>0.001057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.135864</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.004834</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>0.013828</td>\n",
       "      <td>0.002200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.037439</td>\n",
       "      <td>0.049738</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.008839</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.079697</td>\n",
       "      <td>0.002646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.029211</td>\n",
       "      <td>0.098473</td>\n",
       "      <td>0.010282</td>\n",
       "      <td>0.008347</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>0.031354</td>\n",
       "      <td>0.004655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tfidf_mnb_0  tfidf_mnb_1  tfidf_mnb_2  tfidf_mnb_3  tfidf_mnb_4  \\\n",
       "0     0.003829     0.180469     0.008034     0.001521     0.001850   \n",
       "1     0.008375     0.123705     0.012833     0.024480     0.004474   \n",
       "2     0.135864     0.029412     0.005488     0.004134     0.004834   \n",
       "3     0.037439     0.049738     0.005405     0.008839     0.008999   \n",
       "4     0.029211     0.098473     0.010282     0.008347     0.010358   \n",
       "\n",
       "   tfidf_mnb_5  tfidf_mnb_6  tfidf_mnb_7  \n",
       "0     0.000902     0.002686     0.000710  \n",
       "1     0.001678     0.023398     0.001057  \n",
       "2     0.004239     0.013828     0.002200  \n",
       "3     0.007237     0.079697     0.002646  \n",
       "4     0.007320     0.031354     0.004655  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2.3 BernoulliNB 提取特征\n",
    "clf = MultinomialNB()\n",
    "stack_all = tfidf_clf_features(clf, X_train, X_test, y_train, y_test, num_class)\n",
    "df_stack = pd.DataFrame(index=range(count))\n",
    "for i in range(stack_all.shape[1]):\n",
    "    df_stack['tfidf_mnb_{}'.format(i)] = stack_all[:, i]\n",
    "df_stack.to_csv(config.feat_tfidf_mnb_prob, index=None, encoding='utf8')\n",
    "df_stack.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
